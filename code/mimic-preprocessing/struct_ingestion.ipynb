{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c7a9be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hdfs in c:\\programdata\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: docopt in c:\\programdata\\anaconda3\\lib\\site-packages (from hdfs) (0.6.2)\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from hdfs) (2.27.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from hdfs) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.7.0->hdfs) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.7.0->hdfs) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.7.0->hdfs) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.7.0->hdfs) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078c4450",
   "metadata": {},
   "outputs": [
    {
     "ename": "HdfsError",
     "evalue": "Invalid value for webhdfs parameter \"user.name\": Invalid value: \"Donato Manco\" does not belong to the domain ^[A-Za-z_][A-Za-z0-9._-]*[$]?$",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHdfsError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m localpath\u001b[38;5;241m=\u001b[39mfile\n\u001b[0;32m     15\u001b[0m path_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root,file)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mhdfsclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdfspath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocalpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hdfs\\client.py:598\u001b[0m, in \u001b[0;36mClient.upload\u001b[1;34m(self, hdfs_path, local_path, n_threads, temp_dir, chunk_size, progress, cleanup, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m     temp_path \u001b[38;5;241m=\u001b[39m hdfs_path\n\u001b[0;32m    596\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;66;03m# An unexpected error occurred.\u001b[39;00m\n\u001b[1;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    600\u001b[0m   \u001b[38;5;66;03m# Remote path is a directory.\u001b[39;00m\n\u001b[0;32m    601\u001b[0m   suffixes \u001b[38;5;241m=\u001b[39m {status[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpathSuffix\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m status \u001b[38;5;129;01min\u001b[39;00m statuses}\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hdfs\\client.py:587\u001b[0m, in \u001b[0;36mClient.upload\u001b[1;34m(self, hdfs_path, local_path, n_threads, temp_dir, chunk_size, progress, cleanup, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m temp_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m   statuses \u001b[38;5;241m=\u001b[39m [status \u001b[38;5;28;01mfor\u001b[39;00m _, status \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdfs_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m]\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HdfsError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    589\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot a directory\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m err\u001b[38;5;241m.\u001b[39mmessage:\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;66;03m# Remote path is a normal file.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hdfs\\client.py:1125\u001b[0m, in \u001b[0;36mClient.list\u001b[1;34m(self, hdfs_path, status)\u001b[0m\n\u001b[0;32m   1123\u001b[0m _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mListing \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, hdfs_path)\n\u001b[0;32m   1124\u001b[0m hdfs_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve(hdfs_path)\n\u001b[1;32m-> 1125\u001b[0m statuses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_list_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdfs_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFileStatuses\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFileStatus\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(statuses) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   1127\u001b[0m   \u001b[38;5;129;01mnot\u001b[39;00m statuses[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpathSuffix\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus(hdfs_path)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFILE\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1128\u001b[0m   \u001b[38;5;66;03m# HttpFS behaves incorrectly here, we sometimes need an extra call to\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m   \u001b[38;5;66;03m# make sure we always identify if we are dealing with a file.\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m ):\n\u001b[0;32m   1131\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m HdfsError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m is not a directory.\u001b[39m\u001b[38;5;124m'\u001b[39m, hdfs_path)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hdfs\\client.py:118\u001b[0m, in \u001b[0;36m_Request.to_method.<locals>.api_handler\u001b[1;34m(client, hdfs_path, data, strict, **params)\u001b[0m\n\u001b[0;32m    116\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m err\u001b[38;5;241m.\u001b[39mexception \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetriableException\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStandbyException\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m strict:\n\u001b[1;32m--> 118\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m    121\u001b[0m attempted_hosts\u001b[38;5;241m.\u001b[39madd(host)\n",
      "\u001b[1;31mHdfsError\u001b[0m: Invalid value for webhdfs parameter \"user.name\": Invalid value: \"Donato Manco\" does not belong to the domain ^[A-Za-z_][A-Za-z0-9._-]*[$]?$"
     ]
    }
   ],
   "source": [
    "# Effettua ingestion dei file strutturati del dataset \"MIMIC III\" in un cluster hadoop\n",
    "\n",
    "import os\n",
    "from hdfs import InsecureClient\n",
    "\n",
    "hdfsclient = InsecureClient('http://localhost:9870')\n",
    "hdfspath=\"/mimic-iii-clinical/\"\n",
    "\n",
    "\n",
    "source = 'C:/Carlo/mimic-iii-demo'\n",
    "\n",
    "for root, dirs, files in os.walk(source):\n",
    "    for file in files:\n",
    "        localpath=file\n",
    "        path_file = os.path.join(root,file)\n",
    "        hdfsclient.upload(hdfspath, localpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2e598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
